{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import time\n",
    "import os\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "import json \n",
    "from datetime import datetime \n",
    "import subprocess\n",
    "from pydub.utils import mediainfo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import time\n",
    "import os\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "import json \n",
    "from datetime import datetime \n",
    "import subprocess\n",
    "from pydub.utils import mediainfo\n",
    "import json\n",
    "import cv2\n",
    "import os, shutil\n",
    "import boto3\n",
    "from io import StringIO\n",
    "import sys\n",
    "import time\n",
    "\n",
    "\n",
    "class VideoDetect:\n",
    "    jobId = ''\n",
    "    rek = boto3.client('rekognition', region_name='ap-south-1')\n",
    "    sqs = boto3.client('sqs', region_name='ap-south-1')\n",
    "    sns = boto3.client('sns', region_name='ap-south-1')\n",
    "\n",
    "    roleArn = ''\n",
    "    bucket = ''\n",
    "    video = ''\n",
    "    startJobId = ''\n",
    "\n",
    "    sqsQueueUrl = ''\n",
    "    snsTopicArn = ''\n",
    "    processType = ''\n",
    "\n",
    "    def __init__(self, role, bucket, video, segment):\n",
    "        self.roleArn = role\n",
    "        self.bucket = bucket\n",
    "        self.video = video\n",
    "        self.segment = segment\n",
    "\n",
    "    def GetSQSMessageSuccess(self):\n",
    "\n",
    "        jobFound = False\n",
    "        succeeded = False\n",
    "\n",
    "        dotLine=0\n",
    "        while jobFound == False:\n",
    "            sqsResponse = self.sqs.receive_message(QueueUrl=self.sqsQueueUrl, MessageAttributeNames=['ALL'],\n",
    "                                                   MaxNumberOfMessages=10)\n",
    "\n",
    "            if sqsResponse:\n",
    "\n",
    "                if 'Messages' not in sqsResponse:\n",
    "                    if dotLine<40:\n",
    "                        print('.', end='')\n",
    "                        dotLine=dotLine+1\n",
    "                    else:\n",
    "                        print()\n",
    "                        dotLine=0\n",
    "                    sys.stdout.flush()\n",
    "                    time.sleep(5)\n",
    "                    continue\n",
    "\n",
    "                for message in sqsResponse['Messages']:\n",
    "                    notification = json.loads(message['Body'])\n",
    "                    rekMessage = json.loads(notification['Message'])\n",
    "                    print(rekMessage['JobId'])\n",
    "                    print(rekMessage['Status'])\n",
    "                    if rekMessage['JobId'] == self.startJobId:\n",
    "                        # print('Matching Job Found:' + rekMessage['JobId'])\n",
    "                        jobFound = True\n",
    "                        if (rekMessage['Status']=='SUCCEEDED'):\n",
    "                            succeeded=True\n",
    "\n",
    "                        self.sqs.delete_message(QueueUrl=self.sqsQueueUrl,\n",
    "                                                ReceiptHandle=message['ReceiptHandle'])\n",
    "                    else:\n",
    "                        pass\n",
    "                        # print(\"Job didn't match:\" +\n",
    "                        #       str(rekMessage['JobId']) + ' : ' + self.startJobId)\n",
    "                    # Delete the unknown message. Consider sending to dead letter queue\n",
    "                    self.sqs.delete_message(QueueUrl=self.sqsQueueUrl,\n",
    "                                            ReceiptHandle=message['ReceiptHandle'])\n",
    "\n",
    "\n",
    "        return succeeded\n",
    "\n",
    "    # def StartCelebrityRecognition(self):\n",
    "    def StartContentModeration(self):\n",
    "        # response=self.rek.start_label_detection(Video={'S3Object': {'Bucket': self.bucket, 'Name': self.video}},\n",
    "        #                                         NotificationChannel={'RoleArn': self.roleArn, 'SNSTopicArn': self.snsTopicArn})\n",
    "        # response=self.rek.start_celebrity_recognition(Video={'S3Object': {'Bucket': self.bucket, 'Name': self.video}},\n",
    "        print(self.bucket)\n",
    "        print(self.video)\n",
    "        response=self.rek.start_content_moderation(Video={'S3Object': {'Bucket': self.bucket, 'Name': self.video}},\n",
    "                                                   NotificationChannel={'RoleArn': self.roleArn, 'SNSTopicArn': self.snsTopicArn})\n",
    "\n",
    "        self.startJobId=response['JobId']\n",
    "        # print('Start Job Id: ' + self.startJobId)\n",
    "        \n",
    "    def StartCelebrityRecognition(self):\n",
    "        # response=self.rek.start_label_detection(Video={'S3Object': {'Bucket': self.bucket, 'Name': self.video}},\n",
    "        #                                         NotificationChannel={'RoleArn': self.roleArn, 'SNSTopicArn': self.snsTopicArn})\n",
    "        # response=self.rek.start_celebrity_recognition(Video={'S3Object': {'Bucket': self.bucket, 'Name': self.video}},\n",
    "        print(self.bucket)\n",
    "        print(self.video)\n",
    "        response=self.rek.start_celebrity_recognition(Video={'S3Object': {'Bucket': self.bucket, 'Name': self.video}},\n",
    "                                                   NotificationChannel={'RoleArn': self.roleArn, 'SNSTopicArn': self.snsTopicArn})\n",
    "\n",
    "        self.startJobId=response['JobId']\n",
    "        # print('Start Job Id: ' + self.startJobId)\n",
    "\n",
    "    # def GetCelebrityRecognitionResults(self):\n",
    "    def GetContentModerationResults(self):\n",
    "        maxResults = 100\n",
    "        paginationToken = ''\n",
    "        # finished = False\n",
    "        #\n",
    "        # while finished == False:\n",
    "        response = self.rek.get_content_moderation(JobId=self.startJobId,\n",
    "                                                   MaxResults=maxResults,\n",
    "                                                   NextToken=paginationToken,\n",
    "                                                   SortBy='TIMESTAMP')\n",
    "\n",
    "        print('Codec: ' + response['VideoMetadata']['Codec'])\n",
    "        # print('Duration: ' + str(response['VideoMetadata']['DurationMillis']))\n",
    "        print('Format: ' + response['VideoMetadata']['Format'])\n",
    "        print('Frame rate: ' + str(response['VideoMetadata']['FrameRate']))\n",
    "        print()\n",
    "\n",
    "        result_list = []\n",
    "\n",
    "        for moderation_label_info in response['ModerationLabels']:\n",
    "            moderation_label_dict = {}\n",
    "            segment_offset_seconds = (self.segment - 1) * 60000\n",
    "            timestamp = moderation_label_info[\"Timestamp\"]\n",
    "            timestamp += segment_offset_seconds\n",
    "            label_name = moderation_label_info[\"ModerationLabel\"][\"Name\"]\n",
    "            confidence = moderation_label_info[\"ModerationLabel\"][\"Confidence\"]\n",
    "\n",
    "            moderation_label_dict['timestamp'] = timestamp\n",
    "            moderation_label_dict['Moderated Label Name'] = label_name\n",
    "            moderation_label_dict['Confidence'] = confidence\n",
    "\n",
    "            result_list.append(moderation_label_dict)\n",
    "\n",
    "            print('Timestamp: ', timestamp, '\\tModerated Label: ', label_name, \"\\t Confidence: \", confidence)\n",
    "        return result_list\n",
    "    \n",
    "    def GetCelebrityRekognitionResults(self):\n",
    "        maxResults = 100\n",
    "        paginationToken = ''\n",
    "        # finished = False\n",
    "        #\n",
    "        # while finished == False:\n",
    "        response = self.rek.get_celebrity_recognition(JobId=self.startJobId,\n",
    "                                                   MaxResults=maxResults,\n",
    "                                                   NextToken=paginationToken,\n",
    "                                                   SortBy='TIMESTAMP')\n",
    "\n",
    "        print('Codec: ' + response['VideoMetadata']['Codec'])\n",
    "        # print('Duration: ' + str(response['VideoMetadata']['DurationMillis']))\n",
    "        print('Format: ' + response['VideoMetadata']['Format'])\n",
    "        print('Frame rate: ' + str(response['VideoMetadata']['FrameRate']))\n",
    "        print()\n",
    "\n",
    "        result_list = []\n",
    "\n",
    "        for celeb_name in response['Celebrities']:\n",
    "            celeb_dict = {}\n",
    "            segment_offset_seconds = (self.segment - 1) * 60000\n",
    "            timestamp = celeb_name[\"Timestamp\"]\n",
    "            timestamp += segment_offset_seconds\n",
    "            name = celeb_name[\"Celebrity\"][\"Name\"]\n",
    "            confidence = celeb_name[\"Celebrity\"][\"Confidence\"]\n",
    "\n",
    "            celeb_dict['timestamp'] = timestamp\n",
    "            celeb_dict['Celeb Name'] = name\n",
    "            celeb_dict['Confidence'] = confidence\n",
    "\n",
    "            result_list.append(celeb_dict)\n",
    "\n",
    "            # print('Timestamp: ', timestamp, '\\tModerated Label: ', label_name, \"\\t Confidence: \", confidence)\n",
    "        return result_list\n",
    "\n",
    "\n",
    "    def CreateTopicandQueue(self):\n",
    "\n",
    "        millis = str(int(round(time.time() * 1000)))\n",
    "\n",
    "        #Create SNS topic\n",
    "\n",
    "        snsTopicName=\"AmazonRekognitionExample\" + millis\n",
    "\n",
    "        topicResponse=self.sns.create_topic(Name=snsTopicName)\n",
    "        self.snsTopicArn = topicResponse['TopicArn']\n",
    "\n",
    "        #create SQS queue\n",
    "        sqsQueueName=\"AmazonRekognitionQueue\" + millis\n",
    "        self.sqs.create_queue(QueueName=sqsQueueName)\n",
    "        self.sqsQueueUrl = self.sqs.get_queue_url(QueueName=sqsQueueName)['QueueUrl']\n",
    "\n",
    "        attribs = self.sqs.get_queue_attributes(QueueUrl=self.sqsQueueUrl,\n",
    "                                                AttributeNames=['QueueArn'])['Attributes']\n",
    "\n",
    "        sqsQueueArn = attribs['QueueArn']\n",
    "\n",
    "        # Subscribe SQS queue to SNS topic\n",
    "        self.sns.subscribe(\n",
    "            TopicArn=self.snsTopicArn,\n",
    "            Protocol='sqs',\n",
    "            Endpoint=sqsQueueArn)\n",
    "\n",
    "        #Authorize SNS to write SQS queue\n",
    "        policy = \"\"\"{{\n",
    "  \"Version\":\"2012-10-17\",\n",
    "  \"Statement\":[\n",
    "    {{\n",
    "      \"Sid\":\"MyPolicy\",\n",
    "      \"Effect\":\"Allow\",\n",
    "      \"Principal\" : {{\"AWS\" : \"*\"}},\n",
    "      \"Action\":\"SQS:SendMessage\",\n",
    "      \"Resource\": \"{}\",\n",
    "      \"Condition\":{{\n",
    "        \"ArnEquals\":{{\n",
    "          \"aws:SourceArn\": \"{}\"\n",
    "        }}\n",
    "      }}\n",
    "    }}\n",
    "  ]\n",
    "}}\"\"\".format(sqsQueueArn, self.snsTopicArn)\n",
    "\n",
    "        response = self.sqs.set_queue_attributes(\n",
    "            QueueUrl = self.sqsQueueUrl,\n",
    "            Attributes = {\n",
    "                'Policy' : policy\n",
    "            })\n",
    "\n",
    "    def DeleteTopicandQueue(self):\n",
    "        self.sqs.delete_queue(QueueUrl=self.sqsQueueUrl)\n",
    "        self.sns.delete_topic(TopicArn=self.snsTopicArn)\n",
    "\n",
    "\n",
    "def delete_temp_file(file_path):\n",
    "    try:\n",
    "        if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "            os.unlink(file_path)\n",
    "        elif os.path.isdir(file_path):\n",
    "            shutil.rmtree(file_path)\n",
    "    except Exception as e:\n",
    "        print('Failed to delete %s. Reason: %s' % (file_path, e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoDetect:\n",
    "\n",
    "    jobId = ''\n",
    "\n",
    "    rek = boto3.client('rekognition', region_name='ap-south-1')\n",
    "\n",
    "    sqs = boto3.client('sqs', region_name='ap-south-1')\n",
    "\n",
    "    sns = boto3.client('sns', region_name='ap-south-1')\n",
    "\n",
    " \n",
    "\n",
    "    roleArn = ''\n",
    "\n",
    "    bucket = ''\n",
    "\n",
    "    video = ''\n",
    "\n",
    "    startJobId = ''\n",
    "\n",
    " \n",
    "\n",
    "    sqsQueueUrl = ''\n",
    "\n",
    "    snsTopicArn = ''\n",
    "\n",
    "    processType = ''\n",
    "\n",
    " \n",
    "\n",
    "    def __init__(self, role, bucket, video, segment):\n",
    "\n",
    "        self.roleArn = role\n",
    "\n",
    "        self.bucket = bucket\n",
    "\n",
    "        self.video = video\n",
    "\n",
    "        self.segment = segment\n",
    "\n",
    " \n",
    "\n",
    "    def GetSQSMessageSuccess(self):\n",
    "\n",
    " \n",
    "\n",
    "        jobFound = False\n",
    "\n",
    "        succeeded = False\n",
    "\n",
    " \n",
    "\n",
    "        dotLine=0\n",
    "\n",
    "        while jobFound == False:\n",
    "\n",
    "            sqsResponse = self.sqs.receive_message(QueueUrl=self.sqsQueueUrl, MessageAttributeNames=['ALL'],\n",
    "\n",
    "                                                   MaxNumberOfMessages=10)\n",
    "\n",
    " \n",
    "\n",
    "            if sqsResponse:\n",
    "\n",
    " \n",
    "\n",
    "                if 'Messages' not in sqsResponse:\n",
    "\n",
    "                    if dotLine<40:\n",
    "\n",
    "                        print('.', end='')\n",
    "\n",
    "                        dotLine=dotLine+1\n",
    "\n",
    "                    else:\n",
    "\n",
    "                        print()\n",
    "\n",
    "                        dotLine=0\n",
    "\n",
    "                    sys.stdout.flush()\n",
    "\n",
    "                    time.sleep(5)\n",
    "\n",
    "                    continue\n",
    "\n",
    " \n",
    "\n",
    "                for message in sqsResponse['Messages']:\n",
    "\n",
    "                    notification = json.loads(message['Body'])\n",
    "\n",
    "                    rekMessage = json.loads(notification['Message'])\n",
    "\n",
    "                    print(rekMessage['JobId'])\n",
    "\n",
    "                    print(rekMessage['Status'])\n",
    "\n",
    "                    if rekMessage['JobId'] == self.startJobId:\n",
    "\n",
    "                        # print('Matching Job Found:' + rekMessage['JobId'])\n",
    "\n",
    "                        jobFound = True\n",
    "\n",
    "                        if (rekMessage['Status']=='SUCCEEDED'):\n",
    "\n",
    "                            succeeded=True\n",
    "\n",
    " \n",
    "\n",
    "                        self.sqs.delete_message(QueueUrl=self.sqsQueueUrl,\n",
    "\n",
    "                                                ReceiptHandle=message['ReceiptHandle'])\n",
    "\n",
    "                    else:\n",
    "\n",
    "                        pass\n",
    "\n",
    "                        # print(\"Job didn't match:\" +\n",
    "\n",
    "                        #       str(rekMessage['JobId']) + ' : ' + self.startJobId)\n",
    "\n",
    "                    # Delete the unknown message. Consider sending to dead letter queue\n",
    "\n",
    "                    self.sqs.delete_message(QueueUrl=self.sqsQueueUrl,\n",
    "\n",
    "                                            ReceiptHandle=message['ReceiptHandle'])\n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    "        return succeeded\n",
    "\n",
    " \n",
    "\n",
    "    # def StartCelebrityRecognition(self):\n",
    "\n",
    "    def StartContentModeration(self):\n",
    "\n",
    "        # response=self.rek.start_label_detection(Video={'S3Object': {'Bucket': self.bucket, 'Name': self.video}},\n",
    "\n",
    "        #                                         NotificationChannel={'RoleArn': self.roleArn, 'SNSTopicArn': self.snsTopicArn})\n",
    "\n",
    "        # response=self.rek.start_celebrity_recognition(Video={'S3Object': {'Bucket': self.bucket, 'Name': self.video}},\n",
    "\n",
    "        print(self.bucket)\n",
    "\n",
    "        print(self.video)\n",
    "\n",
    "        response=self.rek.start_content_moderation(Video={'S3Object': {'Bucket': self.bucket, 'Name': self.video}},\n",
    "\n",
    "                                                   NotificationChannel={'RoleArn': self.roleArn, 'SNSTopicArn': self.snsTopicArn})\n",
    "\n",
    " \n",
    "\n",
    "        self.startJobId=response['JobId']\n",
    "\n",
    "        # print('Start Job Id: ' + self.startJobId)\n",
    "\n",
    " \n",
    "\n",
    "    # def GetCelebrityRecognitionResults(self):\n",
    "\n",
    "    def GetContentModerationResults(self):\n",
    "\n",
    "        maxResults = 100\n",
    "\n",
    "        paginationToken = ''\n",
    "\n",
    "        # finished = False\n",
    "\n",
    "        #\n",
    "\n",
    "        # while finished == False:\n",
    "\n",
    "        response = self.rek.get_content_moderation(JobId=self.startJobId,\n",
    "\n",
    "                                                   MaxResults=maxResults,\n",
    "\n",
    "                                                   NextToken=paginationToken,\n",
    "\n",
    "                                                   SortBy='TIMESTAMP')\n",
    "\n",
    " \n",
    "\n",
    "        print('Codec: ' + response['VideoMetadata']['Codec'])\n",
    "\n",
    "        # print('Duration: ' + str(response['VideoMetadata']['DurationMillis']))\n",
    "\n",
    "        print('Format: ' + response['VideoMetadata']['Format'])\n",
    "\n",
    "        print('Frame rate: ' + str(response['VideoMetadata']['FrameRate']))\n",
    "\n",
    "        print()\n",
    "\n",
    " \n",
    "\n",
    "        result_list = []\n",
    "\n",
    " \n",
    "\n",
    "        for moderation_label_info in response['ModerationLabels']:\n",
    "\n",
    "            moderation_label_dict = {}\n",
    "\n",
    "            segment_offset_seconds = (self.segment - 1) * 60000\n",
    "\n",
    "            timestamp = moderation_label_info[\"Timestamp\"]\n",
    "\n",
    "            timestamp += segment_offset_seconds\n",
    "\n",
    "            label_name = moderation_label_info[\"ModerationLabel\"][\"Name\"]\n",
    "\n",
    "            confidence = moderation_label_info[\"ModerationLabel\"][\"Confidence\"]\n",
    "\n",
    " \n",
    "\n",
    "            milliseconds = timestamp\n",
    "\n",
    "            seconds, milliseconds = divmod(milliseconds, 1000)\n",
    "\n",
    "            minutes, seconds = divmod(seconds, 60)\n",
    "\n",
    "            hours, minutes = divmod(minutes, 60)\n",
    "\n",
    "            millisecond_223344= f\"{hours:02d}:{minutes:02d}:{seconds:02d}\"\n",
    "\n",
    " \n",
    "\n",
    "            moderation_label_dict['timestamp_in_Hours_min_sec_format']=millisecond_223344\n",
    "\n",
    "            moderation_label_dict['timestamp'] = timestamp\n",
    "\n",
    "            moderation_label_dict['Moderated Label Name'] = label_name\n",
    "\n",
    "            moderation_label_dict['Confidence'] = confidence\n",
    "\n",
    " \n",
    "\n",
    "            result_list.append(moderation_label_dict)\n",
    "\n",
    " \n",
    "\n",
    "            print('Timestamp: ', timestamp, '\\tModerated Label: ', label_name, \"\\t Confidence: \", confidence)\n",
    "\n",
    "        return result_list\n",
    "\n",
    " \n",
    "\n",
    "    def CreateTopicandQueue(self):\n",
    "\n",
    " \n",
    "\n",
    "        millis = str(int(round(time.time() * 1000)))\n",
    "\n",
    " \n",
    "\n",
    "        #Create SNS topic\n",
    "\n",
    " \n",
    "\n",
    "        snsTopicName=\"AmazonRekognitionExample\" + millis\n",
    "\n",
    " \n",
    "\n",
    "        topicResponse=self.sns.create_topic(Name=snsTopicName)\n",
    "\n",
    "        self.snsTopicArn = topicResponse['TopicArn']\n",
    "\n",
    " \n",
    "\n",
    "        #create SQS queue\n",
    "\n",
    "        sqsQueueName=\"AmazonRekognitionQueue\" + millis\n",
    "\n",
    "        self.sqs.create_queue(QueueName=sqsQueueName)\n",
    "\n",
    "        self.sqsQueueUrl = self.sqs.get_queue_url(QueueName=sqsQueueName)['QueueUrl']\n",
    "\n",
    " \n",
    "\n",
    "        attribs = self.sqs.get_queue_attributes(QueueUrl=self.sqsQueueUrl,\n",
    "\n",
    "                                                AttributeNames=['QueueArn'])['Attributes']\n",
    "\n",
    " \n",
    "\n",
    "        sqsQueueArn = attribs['QueueArn']\n",
    "\n",
    " \n",
    "\n",
    "        # Subscribe SQS queue to SNS topic\n",
    "\n",
    "        self.sns.subscribe(\n",
    "\n",
    "            TopicArn=self.snsTopicArn,\n",
    "\n",
    "            Protocol='sqs',\n",
    "\n",
    "            Endpoint=sqsQueueArn)\n",
    "\n",
    " \n",
    "\n",
    "        #Authorize SNS to write SQS queue\n",
    "\n",
    "        policy = \"\"\"{{\n",
    "\n",
    "  \"Version\":\"2012-10-17\",\n",
    "\n",
    "  \"Statement\":[\n",
    "\n",
    "    {{\n",
    "\n",
    "      \"Sid\":\"MyPolicy\",\n",
    "\n",
    "      \"Effect\":\"Allow\",\n",
    "\n",
    "      \"Principal\" : {{\"AWS\" : \"*\"}},\n",
    "\n",
    "      \"Action\":\"SQS:SendMessage\",\n",
    "\n",
    "      \"Resource\": \"{}\",\n",
    "\n",
    "      \"Condition\":{{\n",
    "\n",
    "        \"ArnEquals\":{{\n",
    "\n",
    "          \"aws:SourceArn\": \"{}\"\n",
    "\n",
    "        }}\n",
    "\n",
    "      }}\n",
    "\n",
    "    }}\n",
    "\n",
    "  ]\n",
    "\n",
    "}}\"\"\".format(sqsQueueArn, self.snsTopicArn)\n",
    "\n",
    " \n",
    "\n",
    "        response = self.sqs.set_queue_attributes(\n",
    "\n",
    "            QueueUrl = self.sqsQueueUrl,\n",
    "\n",
    "            Attributes = {\n",
    "\n",
    "                'Policy' : policy\n",
    "\n",
    "            })\n",
    "\n",
    " \n",
    "\n",
    "    def DeleteTopicandQueue(self):\n",
    "\n",
    "        self.sqs.delete_queue(QueueUrl=self.sqsQueueUrl)\n",
    "\n",
    "        self.sns.delete_topic(TopicArn=self.snsTopicArn)\n",
    "\n",
    "/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun_yolo_custom_model(classes, model_path, video_path):\n",
    "    model = torch.hub.load('ultralytics/yolov5', 'custom', path = model_path)\n",
    "    # video_path = 'test.mp4'\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    second_results = []\n",
    "\n",
    "    for second in range(int(frame_count / frame_rate)):\n",
    "        start_frame = int(second * frame_rate)\n",
    "        end_frame = int((second + 1) * frame_rate) - 1\n",
    "\n",
    "        total_confidence = 0\n",
    "        monument_names = set()\n",
    "\n",
    "        for frame_idx in range(start_frame, end_frame + 1):\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # Convert the frame to PIL Image\n",
    "            image = Image.fromarray(frame)\n",
    "\n",
    "            # Perform detection on the frame\n",
    "            results = model(image)\n",
    "\n",
    "            for nested_result_list in results.xywhn:\n",
    "                for result_tensor in nested_result_list:\n",
    "                    class_index = int(result_tensor[-1])\n",
    "                    class_probability = float(result_tensor[-2])\n",
    "                    monument_name = classes[class_index]\n",
    "                    \n",
    "                    total_confidence += class_probability\n",
    "                    monument_names.add(monument_name)\n",
    "\n",
    "        avg_confidence = total_confidence / frame_rate\n",
    "        timestamp = time.strftime(\"%H:%M:%S\", time.gmtime(second))\n",
    "        monument_names_str = ', '.join(monument_names)\n",
    "\n",
    "        if monument_names:\n",
    "            second_results.append({\n",
    "                'timestamp': timestamp,\n",
    "                'monument_names': monument_names_str,\n",
    "                'confidence': avg_confidence\n",
    "            })\n",
    "    \n",
    "    cap.release()\n",
    "\n",
    "    return second_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_video_to_wav(video_path):\n",
    "    video_data = mediainfo(video_path)\n",
    "    channels = video_data[\"channels\"]\n",
    "    bit_rate = video_data[\"bit_rate\"]\n",
    "    sample_rate = video_data[\"sample_rate\"]\n",
    "    wav_output = video_path.replace(\".mp4\",\".wav\").replace(\"video\",\"wav_file\")\n",
    "\n",
    "    ffmpeg_cmd = ['ffmpeg', '-i', video_path,  '-b:a', bit_rate, '-ar', sample_rate , '-ac', channels ,'-vn', wav_output]\n",
    "    \n",
    "    try:\n",
    "        subprocess.check_output(ffmpeg_cmd, stderr=subprocess.STDOUT)\n",
    "        print(\"Video converted to WAV successfully!\")\n",
    "        return wav_output\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(\"Error converting video to WAV:\", e.output)\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def transcribe(key,region,lang,path_in,path_out=\"out.txt\",newLine=False):auto_detect_source_language_config\n",
    "def transcribe(key,region,auto_detect_source_language_config,path_in,path_out=\"out.txt\",newLine=False):\n",
    "    # lang = auto_detect_source_language_config\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=key, region=region)\n",
    "    # speech_config.speech_recognition_language=lang\n",
    "    speech_config.output_format = speechsdk.OutputFormat(1)\n",
    "    speech_config.request_word_level_timestamps()\n",
    "    audio_config = speechsdk.AudioConfig(filename=path_in)\n",
    "    speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config,auto_detect_source_language_config=auto_detect_source_language_config, audio_config=audio_config)\n",
    "    done = False\n",
    "    tep_text_json = []\n",
    "    textOut = \"\"\n",
    "    def stop_cb(evt):\n",
    "        print(1)\n",
    "        print(evt)\n",
    "        speech_recognizer.stop_continuous_recognition()\n",
    "        nonlocal done\n",
    "        done = True\n",
    "\n",
    "    str_newLine = \"\"\n",
    "    if newLine:\n",
    "        str_newLine = \" \\n\"\n",
    "\n",
    "    def outPrint(evt):\n",
    "        nonlocal textOut\n",
    "        nonlocal tep_text_json\n",
    "        tmp_text = evt.result.text\n",
    "        tmp_timestamp = evt.result.offset\n",
    "        tmp_duration_ts = evt.result.duration\n",
    "        textOut += f\"[{tmp_timestamp}] [{tmp_duration_ts}] {tmp_text}\" + str_newLine\n",
    "        \n",
    "        out = eval(evt.result.json)\n",
    "        tep_text_json.append(out)\n",
    "        # print(2)\n",
    "        # print(tmp_text)\n",
    "        # print(3)\n",
    "        # print(tmp_timestamp)\n",
    "        # print(4)\n",
    "        # print(tmp_duration_ts)\n",
    "        # print(5)\n",
    "        # print('-' * 100)\n",
    "        # print(evt)\n",
    "        # print('-' * 100)\n",
    "        # print(evt.result)\n",
    "        # print('-' * 100)\n",
    "        # print(\"haa yahi h be\")\n",
    "        # print(evt.result.json)\n",
    "        # out = eval(evt.result.json)\n",
    "        # print(type(out))\n",
    "        # print(out)\n",
    "        # print('-' * 100)\n",
    "        # print(evt.result.properties)\n",
    "        # print('-' * 100)\n",
    "        # print(dir(evt))\n",
    "        # print('-' * 100)\n",
    "        # print(dir(evt.result))\n",
    "    \n",
    "    speech_recognizer.recognized.connect(outPrint)\n",
    "    speech_recognizer.session_stopped.connect(stop_cb)\n",
    "    speech_recognizer.start_continuous_recognition()\n",
    "\n",
    "    while not done:\n",
    "        time.sleep(.5)\n",
    "    # with open(path_out, 'w', encoding='utf-16') as f:\n",
    "    #     f.write(textOut)\n",
    "    # tep_text_json = str(tep_text_json)\n",
    "    # path_out=\"./\"\n",
    "    print(\"tep_text_json:\",tep_text_json)\n",
    "    json_data = json.dumps(tep_text_json)\n",
    "    print(\"json_data:\",json_data)\n",
    "    with open(path_out, 'w', encoding='utf-16') as f:\n",
    "        f.write(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def milliseconds_to_srt_timestamp(milliseconds):\n",
    "    total_seconds = milliseconds // 1000\n",
    "    # milliseconds %= 1000\n",
    "    # minutes = seconds // 60\n",
    "    # seconds %= 60\n",
    "    hours = total_seconds // 3600\n",
    "    minutes = (total_seconds % 3600) // 60\n",
    "    seconds = total_seconds % 60\n",
    "    milliseconds = milliseconds % 1000\n",
    "    # minutes %= 60\n",
    "    return '{:02d}:{:02d}:{:02d},{:03d}'.format(hours, minutes, seconds, milliseconds)\n",
    "\n",
    "\n",
    "# json_file = \"D:/Python_scripts/speech_to_test_azure/New folder/txt_&_json_file/txt_&_json_file/Piyush_2.json\"  # Replace with the path to your JSON file\n",
    "def convert_json_into_words_by_words_list(json_file):\n",
    "    with open(json_file, \"r\",encoding='utf-16') as file:\n",
    "        json_output = file.read()\n",
    "\n",
    "    data = json.loads(json_output)\n",
    "    # print(len(data))\n",
    "    srt_content = \"\"\n",
    "    list_of_words = []\n",
    "    for j in range(len(data)):\n",
    "        # print(j)\n",
    "    # Extract word-level details\n",
    "        words = data[j][\"NBest\"][0][\"Words\"]\n",
    "\n",
    "    # Generate SRT content\n",
    "        for i, word in enumerate(words):\n",
    "            list_with_time =[]\n",
    "            start_timestamp = milliseconds_to_srt_timestamp(word[\"Offset\"] // 10000)\n",
    "            end_timestamp = milliseconds_to_srt_timestamp((word[\"Offset\"]  + word[\"Duration\"]) // 10000)\n",
    "            subtitle_text = word[\"Word\"]\n",
    "            srt_entry = f\"{i+1}\\n{start_timestamp} --> {end_timestamp}\\n{subtitle_text}\\n\\n\"\n",
    "            srt_content += srt_entry\n",
    "            list_with_time.append(start_timestamp)\n",
    "            list_with_time.append(end_timestamp)\n",
    "            list_with_time.append(subtitle_text)\n",
    "            list_of_words.append(list_with_time)\n",
    "    json_data = json.dumps(list_of_words)\n",
    "    with open(\"./list_of_words.json\",\"w\",encoding=\"utf-16\") as f:\n",
    "        f.write(json_data)\n",
    "    return list_of_words\n",
    "\n",
    "# json_file = \"D:/Python_scripts/speech_to_test_azure/srt_fol/pm_modi.json\"\n",
    "\n",
    "# list_of_words = convert_json_into_words_by_words_list(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convert_time_stamp_to_seconds(time_stamp):\n",
    "    time_format = \"%H:%M:%S,%f\"\n",
    "\n",
    "    # Convert the time stamp to a datetime object\n",
    "    time_obj = datetime.strptime(time_stamp, time_format)\n",
    "\n",
    "    # Calculate the total number of seconds\n",
    "    seconds = time_obj.hour * 3600 + time_obj.minute * 60 + time_obj.second + time_obj.microsecond / 1000000\n",
    "\n",
    "    return seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_srt_file(list_of_words,filename):\n",
    "\n",
    "    list_of_new_srt = []\n",
    "    str_of_words = \"\"\n",
    "    total_words_covered = 0\n",
    "    index = 1\n",
    "    srt_sentence = \"\"\n",
    "\n",
    "    list_for_sentences_for_the_final_srt =[]\n",
    "    while total_words_covered != len(list_of_words):\n",
    "        transcription_list = []\n",
    "        start_point = convert_time_stamp_to_seconds(list_of_words[total_words_covered][0])\n",
    "        start_for_srt = list_of_words[total_words_covered][0]\n",
    "\n",
    "        transcription_list.append(list_of_words[total_words_covered][2])\n",
    "        total_words_covered += 1\n",
    "\n",
    "        \n",
    "        list_for_srt_by_sentence = []\n",
    "        \n",
    "        dict = {}\n",
    "\n",
    "        # DECIDE AN END FOR START WORD\n",
    "\n",
    "        for j in range(total_words_covered, (len(list_of_words) - 1)):\n",
    "\n",
    "            end_point =convert_time_stamp_to_seconds(list_of_words[j][1])\n",
    "            end_for_srt = list_of_words[j][1]\n",
    "            end_for_prev_srt = list_of_words[j - 1][1]\n",
    "        \n",
    "            time_limit = round(((end_point) - (start_point)),3)\n",
    "            \n",
    "            \n",
    "            # bin_size\n",
    "            if time_limit <= (2.50):\n",
    "                transcription_list.append(list_of_words[j][2])\n",
    "                total_words_covered += 1\n",
    "                end_for_srt = list_of_words[j][1]\n",
    "\n",
    "            else:\n",
    "                list_for_srt_by_sentence.append(transcription_list)\n",
    "                dict[\"transcript\"] = transcription_list\n",
    "                dict[\"start_point\"] = start_for_srt\n",
    "                dict[\"end_point\"]  = end_for_prev_srt\n",
    "                break\n",
    "    \n",
    "\n",
    "        list_of_new_srt.append(dict)\n",
    "        str_of_words = \"\"\n",
    "    for transcript_dict in list_of_new_srt:\n",
    "        dict ={}\n",
    "        if \"transcript\" in transcript_dict.keys():\n",
    "            subtitle_text = (' '.join(transcript_dict[\"transcript\"]))\n",
    "            start_time = transcript_dict[\"start_point\"]\n",
    "            end_time = transcript_dict[\"end_point\"] \n",
    "            dict[\"transcript\"] = subtitle_text\n",
    "            dict[\"start_point\"] = start_time\n",
    "            dict[\"end_point\"] = end_time\n",
    "            list_for_sentences_for_the_final_srt.append(dict)\n",
    "\n",
    "    for dict_sentences in list_for_sentences_for_the_final_srt:\n",
    "        # print(dict_sentences)\n",
    "        subtitle_text = dict_sentences[\"transcript\"]\n",
    "        start_timestamp = dict_sentences['start_point']\n",
    "        end_timestamp = dict_sentences['end_point']\n",
    "        srt_entry = f\"{index}\\n{start_timestamp} --> {end_timestamp}\\n{subtitle_text}\\n\\n\"\n",
    "        index +=1\n",
    "        # print(srt_entry)\n",
    "        # break\n",
    "        srt_sentence += srt_entry\n",
    "\n",
    "        # srt_content += \"\"+ srt_entry\n",
    "\n",
    "    filename = filename\n",
    "\n",
    "    with open(filename, 'w') as file:\n",
    "        file.write(srt_sentence)\n",
    "    return srt_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "\n",
    "def split_video_into_segments(input_file, segment_duration=60):\n",
    "    try:\n",
    "        clip = VideoFileClip(input_file)\n",
    "\n",
    "        # Calculate the total duration of the input video in seconds\n",
    "        total_duration = clip.duration\n",
    "\n",
    "        # Calculate the number of segments required\n",
    "        num_segments = int(total_duration / segment_duration)\n",
    "\n",
    "        # Extract the file name and extension from the input_file\n",
    "        file_name, file_extension = input_file.split('.')\n",
    "\n",
    "        # Split the video into segments\n",
    "        for i in range(num_segments):\n",
    "            start_time = i * segment_duration\n",
    "            end_time = min((i + 1) * segment_duration, total_duration)\n",
    "            segment_clip = clip.subclip(start_time, end_time)\n",
    "            output_file = f\"{file_name}_segment_{i + 1}.{file_extension}\"\n",
    "            segment_clip.write_videofile(output_file, codec=\"libx264\")\n",
    "\n",
    "        # For the last segment (if it's shorter than segment_duration)\n",
    "        if total_duration % segment_duration > 0:\n",
    "            start_time = num_segments * segment_duration\n",
    "            end_time = total_duration\n",
    "            last_segment_clip = clip.subclip(start_time, end_time)\n",
    "            output_file = f\"{file_name}_segment_{num_segments + 1}.{file_extension}\"\n",
    "            last_segment_clip.write_videofile(output_file, codec=\"libx264\")\n",
    "\n",
    "        clip.close()\n",
    "        print(\"Video splitting completed successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_video_and_upload_s3(video_path):\n",
    "    cwd = os.getcwd()\n",
    "    listdir_earlier = os.listdir(cwd)\n",
    "    print(listdir_earlier)\n",
    "    # ffmpeg_cmd = ['ffmpeg', '-i', video_path,  '-c', 'copy', '-map 0', '-segment_time' , '00:01:00', \"-f segment -reset_timestamps 1 output%03d.mp4\"]\n",
    "    # ffmpeg_split_cmd = \"\"\"ffmpeg -i '\"\"\" + video_path + \"\"\"' -c copy -map 0 -segment_time 00:01:00 -f segment -reset_timestamps 1 output%03d.mp4\"\"\"\n",
    "    ffmpeg_split_cmd = \"\"\"ffmpeg -i 'video/THOMAS_SHELBY_SMOKING.mp4' -c copy -map 0 -segment_time 00:01:00 -f segment -reset_timestamps 1 output%03d.mp4 > /dump 2>&1\"\"\"\n",
    "    # subprocess.check_output(ffmpeg_cmd, stderr=subprocess.STDOUT)\n",
    "    # subprocess.run(ffmpeg_split_cmd, shell=True, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    try:\n",
    "        print(ffmpeg_split_cmd)\n",
    "        subprocess.check_output(ffmpeg_split_cmd, shell=True, stderr=subprocess.STDOUT)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        raise RuntimeError(\"command '{}' return with error (code {}): {}\".format(e.cmd, e.returncode, e.output))\n",
    "\n",
    "    listdir_now = os.listdir(cwd)\n",
    "    print(listdir_now)\n",
    "\n",
    "    # cmd = 'aws s3 cp D:/Python_scripts/AWS_Scripts/my_function/my_deployment_package.zip s3://alt-cap-logsbucket-12leb47kv5fyr/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_to_s3(video_path):\n",
    "    cmd = 'aws s3 cp \"' + video_path + '\" s3://aws-rekognition-dataset-v2'\n",
    "    # subprocess.run(cmd, shell=True, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "\n",
    "    try:\n",
    "        subprocess.check_output(cmd, shell=True, stderr=subprocess.STDOUT)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        raise RuntimeError(\"command '{}' return with error (code {}): {}\".format(e.cmd, e.returncode, e.output))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_videos_with_nomenclature():\n",
    "    eligible_videos = []\n",
    "    for filename in os.listdir('D:/Demo_Resources/Moderation_AI/video'):\n",
    "        if filename.endswith('.mp4') and '_segment_' in filename:\n",
    "            filename = 'D:/Demo_Resources/Moderation_AI/video/' + str(filename)\n",
    "            eligible_videos.append(filename)\n",
    "            upload_to_s3(filename)  # Upload the video to S3 (you need to implement this function)\n",
    "    return eligible_videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_segment_number(filename):\n",
    "    pattern = r'_segment_(\\d+)\\.mp4'\n",
    "    match = re.search(pattern, filename)\n",
    "    if match:\n",
    "        segment_number = int(match.group(1))\n",
    "        return segment_number\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import os\n",
    "import shutil\n",
    "from moviepy.editor import VideoFileClip\n",
    "    \n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/upload_video', methods=['POST'])\n",
    "def upload_video():\n",
    "    # try: \n",
    "        save_path = 'D:/Demo_Resources/Moderation_AI/video/'\n",
    "        # json_path = 'D:/Demo_Resources/Transcription_AI/Transcript_flask/json_file/'\n",
    "        key = os.get(\"Azure_key\")\n",
    "        region = \"centralindia\"\n",
    "        \n",
    "        auto_detect_source_language_config = speechsdk.languageconfig.AutoDetectSourceLanguageConfig(\n",
    "        languages=[\"en-IN\", \"hi-IN\",])\n",
    "        \n",
    "        # lang = \"en-IN\" # See e.g. https://learn.microsoft.com/en-us/dynamics365/fin-ops-core/dev-itpro/help/language-locale\n",
    "        # path_in = \"09-02-2023 LS-01.wav\"\n",
    "        # path_in = \"D:/Python_scripts/speech_to_test_azure/New folder/pm_modi.wav\"\n",
    "        # path_out = \"D:/Python_scripts/speech_to_test_azure/srt_fol/pm_modi.json\"\n",
    "        # transcribe(key,region,lang,path_in,path_out)\n",
    "        # Check if the 'video' key exists in the request files\n",
    "        if 'video' not in request.files:\n",
    "            return 'No video file found', 400\n",
    "\n",
    "        video_file = request.files['video']\n",
    "\n",
    "        # Save the video to the specified path\n",
    "        video_file.save(save_path + video_file.filename)\n",
    "        path_of_video = (save_path + video_file.filename)\n",
    "        path_of_wav_file = convert_video_to_wav(path_of_video)\n",
    "        # path_of_wav_file = convert_video_to_wav(path_of_video)\n",
    "        \n",
    "        # prefix = os.path.dirname(path_of_video)\n",
    "        # print(prefix)\n",
    "        # print(type(prefix))\n",
    "        \n",
    "        # FOR SRT FROM AZURE CONTINUOUS SPEECH\n",
    "        path_of_json = (json_path + video_file.filename)\n",
    "        path_of_json = path_of_json.replace(\".mp4\",\".json\")\n",
    "        transcribe(key,region,auto_detect_source_language_config,path_of_wav_file,path_of_json)\n",
    "\n",
    "        \n",
    "        list_of_words = convert_json_into_words_by_words_list(path_of_json)\n",
    "        path_of_srt = path_of_video.replace(\"video\",\"srt_file\").replace(\".mp4\",\".srt\")\n",
    "        output_value_of_srt = generate_srt_file(list_of_words,path_of_srt)\n",
    "\n",
    "        split_video_into_segments(path_of_video)\n",
    "        list_video_segments = get_videos_with_nomenclature()\n",
    "\n",
    "        final_output = []\n",
    "\n",
    "        for video_segment in list_video_segments:\n",
    "        # upload_to_s3(path_of_video)\n",
    "\n",
    "            roleArn = 'arn:aws:iam::Account_ID:role/AmazonRekognitionVideoServiceRole'\n",
    "            bucket = 'your_s3_bucket'\n",
    "            # UNCOMMENT THIS FOR SHORT VIDEO\n",
    "            # video = video_file.filename\n",
    "            video = video_segment\n",
    "            video = video.split('/')[-1]\n",
    "            segment = extract_segment_number(video)\n",
    "\n",
    "            print('Content Moderation Summary:')\n",
    "\n",
    "            analyzer = VideoDetect(roleArn, bucket, video, segment)\n",
    "            analyzer.CreateTopicandQueue()\n",
    "\n",
    "            output_value_of_srt = None\n",
    "\n",
    "        # analyzer.StartCelebrityRecognition()\n",
    "            analyzer.StartContentModeration()\n",
    "            for i in range(1):\n",
    "                if analyzer.GetSQSMessageSuccess()==True:\n",
    "                    # analyzer.GetCelebrityRecognitionResults()\n",
    "                    output_value_of_srt = analyzer.GetContentModerationResults()\n",
    "                    print('Right before break!!')\n",
    "                    final_output.append(output_value_of_srt)\n",
    "                    break\n",
    "            analyzer.DeleteTopicandQueue()\n",
    "        for video_segment in list_video_segments:\n",
    "            delete_temp_file(video_segment)\n",
    "        return final_output, 200\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()\n",
    "    # print(\"=\"*100)\n",
    "    # print(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install moviepy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
